### -------------------------------------- ### 
# --- Clean Diatom data from Saul Blanco --- #
### -------------------------------------- ###

# date: 10.09.19 

# In this script I clean the diatom data from Miguel Iglesias
# EPSG = 4055

### --- OVERVIEW --- ###
# 01. Setup
# 02. Data Cleaning
# 03. Taxonomic cleaning
# 04. Final touches
### ---------------- ###

# 01. Setup -------------------------------------------------------------------
# libraries
pacman::p_load(here, 
               dplyr, 
               taxize, 
               magrittr, 
               sf, 
               stringr, 
               data.table, 
               lubridate, 
               tidyr,
               readxl,
               purrr,
               tmap)
tmap_mode("view")

# working director  
setwd(here::here("03_Saul_Blanco"))
setwd("~/01_Uni/03_GetReal/002_WP_02/001_Community Data/003_Saul_Blanco/")
# data input 
file.names <- fs::dir_ls("01_data_raw/")  %>% .[str_detect(.,pattern = ".csv$")]
for (i in 1:length(file.names)) {
        
        x <- fread(file.names[i])
        assign(paste0("dia_saul_",i), x)
        
}
full_species_names <- read_excel("01_data_raw/OMNIDIAFILE.xls", skip = 1, sheet = 1) %>% 
  select(CODE, DENOM) %>% 
  setDT
full_genus_names <- read_excel("01_data_raw/OMNIDIAFILE.xls", sheet = 2) %>% 
  select(CODE, DENOM) %>% 
  setDT

# 02. Data Cleaning -------------------------------------------------------
Spe_vec <- c(15,15,21,21,18)
for (i in 1:5) {
        assign(
                x = paste0(
                        "dia_saul_clean_", i
                          ),
                value = get(paste0("dia_saul_",i)) %>% 
                        gather(key = "CODE", 
                               value = "Rel_Abundance", 
                               -c(1:Spe_vec[i]))
        )
}
for (i in 1:5) {
        assign(
                x     = paste0("dia_saul_clean_prebind_", i),
                value = get(paste0("dia_saul_clean_", i))[c("CODE", "Rel_Abundance", "LAT", "LON", "DATE", "SPI")] %>%
                        
                        filter(Rel_Abundance != 0)
        )
}
dia_saul_clean_prebind_2["Rel_Abundance"] <-
        as.numeric(dia_saul_clean_prebind_2$Rel_Abundance)


full_data <- bind_rows(
        dia_saul_clean_prebind_1,
        dia_saul_clean_prebind_2,
        dia_saul_clean_prebind_3,
        dia_saul_clean_prebind_4,
        dia_saul_clean_prebind_5
)


full_names = bind_rows(full_species_names, full_genus_names)

full_data_02 <- left_join(x = full_data,
                          y = full_names,
                          by = "CODE") %>% setDT


full_data_03 <- full_data_02[, CODE := NULL]
names(full_data_03) <- c("Relative_Abundance", "Y.Coord","X.Coord","date", "spi", "taxon")



full_data_03[, c("year", "season") := 
                     list(
                             year(dmy(date)),
                             ifelse(month(dmy(date)) %in% c(12,1,2), "winter", 
                                    ifelse(
                                            month(dmy(date)) %in% c(3,4,5), "spring",
                                            ifelse(
                                                    month(dmy(date)) %in% c(6,7,8), "summer", "autumn"
                                            )
                                    )
                             ) 
                     )]

# the threshold for SPI is based on taylor et al 2005: Diatoms as indicators of
# water quality in the Jukskei-Crocodile river system in 1956 and 1957, a
# re-analysis of diatom count data generated by BJ Cholnoky.
full_data_03[, pristine := ifelse(spi > 15, 1,0)]

data = full_data_03[, list(
        year,
        season,
        pristine,
        taxon,
        y.coord = Y.Coord,
        x.coord = X.Coord
)]

saveRDS(data, "03_FinalData/01_191217_data_before_taxon_clean_Saul_Blanco.RDS")
data = readRDS("03_FinalData/01_191217_data_before_taxon_clean_Saul_Blanco.RDS")

# 03. Taxonomic cleaning ----------------------------------------------------------

##  obvious violations -- nothing that should be problematic. Some sp. spp, var.  
TU = unique(data$taxon)

# classify with taxize package 
classification.object = classification(TU, db = "gbif")

# save classification.object as backup
saveRDS(classification.object, "03_FinalData/02_191217_classification.object_Saul_Blanco.RDS")
classification.object = readRDS("03_FinalData/02_191216_classification.object_Saul_Blacno.RDS")

# this table will hold all the taxonomic information. Once this is completly
# filled it will be joined with  "data".
taxontable = data.table(
        taxon = TU,
        species = "NA",
        genus = "NA",
        family = "NA",
        order = "NA",
        clean = F
)

# Both scirpts contain cleaning of synonyms or erros from gbif. Sourcing does
# not work properly. Open the file up and run it manually.
clean_diatoms_synonyms.R
clean_gbif_errors.R

# validate rows filled by scripts 
taxontable[order != "NA", clean := T]

# how many are still missing? 
taxontable[clean == F, taxon] %>% length

# create empty variables for loop 
response.vector = NULL
response = c()

# loop that asks wether the results of the classfication look sensible.
for (i in 1:nrow(taxontable)) {
        
        # skip if clean
        if (taxontable$clean[i] == TRUE) {
                next()
        }
        # fill tax object 
        tax = classification.object[taxontable$taxon[i]]
        
        # is a response vector loaded?
        if (!(is.null(response.vector))) {
                response[i] = response.vector[i]
                
                # decline if tax is NA 
        } else if (is.na(tax)) {
                response[i] = ""
                
                # look if the found species is found in the original name 
        } else if (str_detect( names(tax), tax[[1]][nrow(tax[[1]]),1])) {
                
                response[i] = "y"
                
        } else {
                cat(
                        "",
                        "\n",
                        "\ ",
                        names(tax),
                        "\n",
                        "\ ",
                        ifelse(
                                "species" %in% tax[[1]][, 2],
                                tax[[1]][which(tax[[1]][, 2] == "species"), 1],
                                ifelse(
                                        "genus" %in% tax[[1]][, 2],
                                        tax[[1]][which(tax[[1]][, 2] == "genus"), 1],
                                        ifelse("family" %in% tax[[1]][, 2],
                                               tax[[1]][which(tax[[1]][, 2] == "family"), 1],  tax[[1]][1])
                                )
                        ),
                        fill = T
                )
                
                response[i] = readline("good?")
        }
        
        if (response[i] == "y") {
                taxontable$clean[i] = T
                if ("species" %in% tax[[1]]$rank) {
                        spe.row = which(tax[[1]]$rank == "species")
                        taxontable[i, species := tax[[1]]$name[spe.row]]
                }
                if ("genus" %in% tax[[1]]$rank) {
                        spe.row = which(tax[[1]]$rank == "genus")
                        taxontable[i, genus := tax[[1]]$name[spe.row]]
                }
                if ("family" %in% tax[[1]]$rank) {
                        spe.row = which(tax[[1]]$rank == "family")
                        taxontable[i, family := tax[[1]]$name[spe.row]]
                }
                if ("order" %in% tax[[1]]$rank) {
                        spe.row = which(tax[[1]]$rank == "order")
                        taxontable[i, order := tax[[1]]$name[spe.row]]
                }
        }
        if (response[i] == "break")
                break()
}


# now enter new rows to clean_diatoms and clean_gbif_errors
taxontable[order != "NA", clean := T]
taxontable[clean == F, taxon]

# save taxontable 
saveRDS(taxontable, "03_FinalData/04_191217_post_correction_taxontable_Saul_Blacno.RDS")
taxontable = readRDS("03_FinalData/04_191217_post_correction_taxontable_Saul_Blacno.RDS")

# add taxonomical information to data 
data2 = left_join(data,
                  taxontable,
                  by = "taxon") %>% 
  setDT

data2[species == "NA", taxon] %>% unique %>% sort
data2[is.na(species)]
data2[genus == "NA", taxon] %>% unique %>% sort
data2[is.na(genus)]
data2[family == "NA"] %>% unique(by = "taxon")
data2[is.na(family)]
data2[order == "NA", list(taxon,genus, family, order)] %>% unique(by = "taxon")  
data2[is.na(order)]

data2 = data2[!is.na(taxon)]

data2[species == "NA", species := NA]
data2[genus == "NA", genus  := NA]
data2[family == "NA", family := NA]
data2[order == "NA", order := NA]

source("~/01_Uni/03_GetReal/02_WP_02/Community Data/quality_check/lists_of_accepted_orders.R")
mzb.orders = unique(data2[, order])
index = mzb.orders %in% accepted.diatoms
mzb.orders[!index] %>% sort

data4 = data2

saveRDS(data4, "03_FinalData/05_191217_final_taxon_join_Saul_Blanco.RDS")
data4 = readRDS("03_FinalData/05_191217_final_taxon_join_Saul_Blanco.RDS")

# 04. Final touches -------------------------------------------------------

# for the surrogate variables it is easier if I remove missing sites now.
data4 = data4[!is.na(x.coord)]

# create a surrogate site variable 
data4[,site := paste0(y.coord,x.coord)]
data4[,date_surrogate := paste0(year, season)]


unique_sites = unique(data4$site)
unique_dates = unique(data4$date_surrogate) [c(1,2,4,3,6,5,7,8)]

data4[, c("site_id", "date_id") := list(
  map_int(data4$site, ~ which(unique_sites == .x )),
  map_int(data4$date_surrogate, ~ which(unique_dates == .x ))
)]


data4[, site_id2 := case_when(
  nchar(trunc(site_id)) == 1 ~ paste0("0000", site_id),
  nchar(trunc(site_id)) == 2 ~ paste0("000", site_id),
  nchar(trunc(site_id)) == 3 ~ paste0("00", site_id),
  nchar(trunc(site_id)) == 4 ~ paste0("0", site_id),
  nchar(trunc(site_id)) == 5 ~ paste0(site_id))]

data4[, date_id2 := case_when(
  nchar(trunc(date_id)) == 1 ~ paste0("0000", date_id),
  nchar(trunc(date_id)) == 2 ~ paste0("000", date_id),
  nchar(trunc(date_id)) == 3 ~ paste0("00", date_id),
  nchar(trunc(date_id)) == 4 ~ paste0("0", date_id),
  nchar(trunc(date_id)) == 5 ~ paste0(date_id))]

data4[,gr_sample_id := paste0("site_", site_id2, "_date_", date_id2,"_dia_Saul_Blanco")]

n.sample.data = data4[, .(n.samples = length(unique(date_id2))), .(site_id2)]

data5 = data4[n.sample.data, on = "site_id2"]

for (i in seq_along(unique(data5$gr_sample_id))) {
  
  temp.reduced.data = data5[gr_sample_id == unique(gr_sample_id)[i]]
  n.spec = nrow(temp.reduced.data)
  n.gen1 = unique(temp.reduced.data$gen)
  n.gen2 = length(n.gen1)
  n.gen3 = sum(is.na(temp.reduced.data$gen))
  n.gen = ifelse(n.gen3 > 0, sum(n.gen2, n.gen3, -1), n.gen2)
  n.fam1 = unique(temp.reduced.data$fam)
  n.fam2 = length(n.fam1)
  n.fam3 = sum(is.na(temp.reduced.data$fam))
  n.fam = ifelse(n.fam3 > 0, sum(n.fam2, n.fam3, -1), n.fam2)
  n.ord1 = unique(temp.reduced.data$ord)
  n.ord2 = length(n.ord1)
  n.ord3 = sum(is.na(temp.reduced.data$ord))
  n.ord = ifelse(n.ord3 > 0, sum(n.ord2, n.ord3, -1), n.ord2)
  
  data5[gr_sample_id == unique(gr_sample_id)[i],
        c("n.species", "n.genus", "n.family", "n.order") := 
          list(n.spec, n.gen, n.fam, n.ord)
        ]
  
  print(i)        
};beepr::beep()

for (i in seq_along(colnames(data5))) {
  x = pull(data5[,.SD,.SDcols = i])
  y = sum(is.na(x))        
  if (y > 0) print(names(data5)[i])
  
}


data6 = data5[, list(
  gr_sample_id,
  original_site_name = NA,
  date = NA,
  year,
  season,
  site_id,
  date_id,
  species,
  genus,
  family,
  order,
  abundance = NA,
  pristine,
  n.species,
  n.genus,
  n.family,
  n.order,
  x.coord,
  y.coord,
  EPSG = 4055,
  data.set = "dia_Saul_Blanco",
  n.samples
  
)]

final = st_as_sf(data6, coords = c("x.coord", "y.coord"), crs = data6$EPSG[1])
final = st_transform(final, crs = 4326)
test1 = final %>% setDT
test1 = unique(test1, by = "site_id")
test1 = st_as_sf(test1, crs = 4326)
tm_shape(test1) + tm_dots(col = "pristine")

st_write(final, "03_FinalData/06_191217_DIA_Saul_Blanco.gpkg")   
